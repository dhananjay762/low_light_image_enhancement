{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f45c7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2 as cv\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils import *\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D ,UpSampling2D, Flatten, Input, Dropout\n",
    "from keras.optimizers import SGD, Adam, Adadelta, Adagrad\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ab33c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t_images, t_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa95d1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c52ac02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46b6c8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0663cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(os.listdir('./data/train/be_enhanced'))\n",
    "train_image = []\n",
    "for im in train_images:\n",
    "    img = image.load_img('./data/train/be_enhanced/'+ im, color_mode= 'rgb')\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    train_image.append(img)\n",
    "train_df = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5504646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 400, 600, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0123eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_name = []\n",
    "for i in range(len(train_images)):\n",
    "    temp = []\n",
    "    temp.append(train_images[i].split('.')[0])\n",
    "    temp.append(train_images[i].split('.')[1])\n",
    "    train_images_name.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4b2912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10', 'png'], ['100', 'png'], ['101', 'png'], ['102', 'png'], ['103', 'png']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_name[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92167403",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = sorted(os.listdir('./data/train/high'))\n",
    "real_image = []\n",
    "for im in real_images:\n",
    "    img = image.load_img('./data/train/high/'+ im, color_mode= 'rgb')\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    real_image.append(img)\n",
    "real_df = np.array(real_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c198f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 400, 600, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e716e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = train_df\n",
    "xnoised = noise_df[0:420]\n",
    "xtest = noise_df[420:]\n",
    "yreal = real_df[0:420]\n",
    "ytest = real_df[420:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f160b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 400, 600, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnoised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c748c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 400, 600, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "782b9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = sorted(os.listdir('./data/test/be_enhanced'))\n",
    "test_image = []\n",
    "for im in test_images:\n",
    "    img = image.load_img('./data/test/be_enhanced/'+ im, color_mode= 'rgb')\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    test_image.append(img)\n",
    "test_df = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d6c645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images_name = []\n",
    "for i in range(len(test_images)):\n",
    "    temp = []\n",
    "    temp.append(test_images[i].split('.')[0])\n",
    "    temp.append(test_images[i].split('.')[1])\n",
    "    test_images_name.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14d2d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 400, 600, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5323b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 470\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f4945bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f71b5c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 338400000 into shape (470,256,256,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-6c2808f58e57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    296\u001b[0m            [5, 6]])\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 338400000 into shape (470,256,256,3)"
     ]
    }
   ],
   "source": [
    "train_df_reshape = np.reshape(train_df, (train_df.shape[0], 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "595e1a9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 338400000 into shape (470,256,256,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-093e31711cd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m470\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mreal_df_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 338400000 into shape (470,256,256,3)"
     ]
    }
   ],
   "source": [
    "train_df_reshape = train_df.reshape((470, 256, 256, 3))\n",
    "real_df_reshape = real_df.reshape(real_df.shape[0], 256, 256, 3).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9a095e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_dataset = tf.data.Dataset.from_tensor_slices(train_df).batch(BATCH_SIZE)\n",
    "train_real_dataset = tf.data.Dataset.from_tensor_slices(real_df).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e28864c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 400, 600, 3), types: tf.float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_noisy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7ddc4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 400, 600, 3), types: tf.float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_real_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bc5231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    \n",
    "    input_img = Input(shape=(256,256,3), name='image_input')\n",
    "#     #Detail Enhancement - CNN\n",
    "#     re_conv1 = tf.layers.conv2d(a_input, 64, 3, 1, padding='same', activation=tf.nn.relu)\n",
    "#     re_conv2 = tf.layers.conv2d(re_conv1, 64, 3, 1, padding='same', activation=tf.nn.relu)\n",
    "#     re_conv3 = tf.layers.conv2d(re_conv2, 64, 3, 1, padding='same', activation=tf.nn.relu)\n",
    "#     re_conv4 = tf.layers.conv2d(re_conv3, 64, 3, 1, padding='same', activation=tf.nn.relu)\n",
    "#     #Mix Channel\n",
    "#     output = tf.layers.conv2d(re_conv4, 1, 3, 1, padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv2')(x)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3')(x)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv4')(x)\n",
    "    x = Conv2D(3, (3,3), activation='relu', padding='same', name='Conv5')(x)\n",
    "    \n",
    "    generator = Model(inputs=input_img, outputs=x)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58981945",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf8dee77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv2D)               (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 256, 256, 3)       1731      \n",
      "=================================================================\n",
      "Total params: 114,307\n",
      "Trainable params: 114,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a7bb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    \n",
    "#     model = tf.keras.Sequential()\n",
    "#     model.add(layers.Conv2D(16, (5, 5), strides=(2, 2), padding='same',\n",
    "#                                      input_shape=[256, 256, 3]))\n",
    "#     model.add(layers.LeakyReLU())\n",
    "#     model.add(layers.Dropout(0.3))\n",
    "\n",
    "#     model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same'))\n",
    "#     model.add(layers.LeakyReLU())\n",
    "#     model.add(layers.Dropout(0.3))\n",
    "\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(1))\n",
    "    \n",
    "#     return model\n",
    "    \n",
    "    input_img = Input(shape=(256,256,3), name='image_input')\n",
    "    \n",
    "    #enoder \n",
    "    x = Conv2D(16, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv2')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    \n",
    "    discriminator = Model(inputs=input_img, outputs=x)\n",
    "    return discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6be00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "400c6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 256, 256, 32)      4640      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2097152)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2097153   \n",
      "=================================================================\n",
      "Total params: 2,102,241\n",
      "Trainable params: 2,102,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80452ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aed2fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "535d8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e6bf5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "271aaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(noisy_images, normal_images):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noisy_images, training=True)\n",
    "        print('generated_images_shape: {}'.format(generated_images.shape))\n",
    "        print('normal_images_shape: {}'.format(normal_images.shape))\n",
    "        \n",
    "        real_output = discriminator(normal_images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32b601f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_noisy_dataset, train_real_dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for train_batch, real_batch in zip(train_noisy_dataset, train_real_dataset):\n",
    "            train_step(train_batch, real_batch)\n",
    "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eae79527",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5765d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(train_noisy_dataset, train_real_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8a09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0ca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b70378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "98422aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D ,UpSampling2D, Flatten, Input\n",
    "from keras.optimizers import SGD, Adam, Adadelta, Adagrad\n",
    "from keras import backend as K\n",
    "\n",
    "def autoencoder():\n",
    "    \n",
    "    input_img = Input(shape=(256,256,3), name='image_input')\n",
    "    \n",
    "    #enoder \n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n",
    "    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv2')(x)\n",
    "    x = MaxPooling2D((2,2), padding='same', name='pool2')(x)\n",
    "    \n",
    "    #decoder\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv5')(x)\n",
    "    x = UpSampling2D((2,2), name='upsample1')(x)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv6')(x)\n",
    "    x = UpSampling2D((2,2), name='upsample2')(x)\n",
    "    x = Conv2D(3, (3,3), activation='sigmoid', padding='same', name='Conv9')(x)\n",
    "    \n",
    "    #model\n",
    "    autoencoder = Model(inputs=input_img, outputs=x)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#     autoencoder.compile(optimizer='adam', loss=ssim_loss(input_img, x))\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "eedc9383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling2D)     (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv6 (Conv2D)               (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "upsample2 (UpSampling2D)     (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv9 (Conv2D)               (None, 256, 256, 3)       1731      \n",
      "=================================================================\n",
      "Total params: 114,307\n",
      "Trainable params: 114,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= autoencoder()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "81fcd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epoch = 50\n",
    "# checkpoint_path = './dae_checkpoint2/cp-{epoch:04d}.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "25d922b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_path, \n",
    "#     verbose=1, \n",
    "#     save_weights_only=True,\n",
    "#     save_freq=xnoised.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7879a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fdbb092d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"image_input_35:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (10, 400, 600, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"image_input_35:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (10, 400, 600, 3).\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6397WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"image_input_35:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (10, 400, 600, 3).\n",
      "42/42 [==============================] - 283s 7s/step - loss: 0.6397 - val_loss: 0.5967\n",
      "Epoch 2/5\n",
      " 2/42 [>.............................] - ETA: 2:14 - loss: 0.6127"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-a2767495592d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxnoised\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxnoised\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "    model.fit(x=xnoised, y=xnoised, epochs=epoch, batch_size=batch_size, validation_data=(xtest, xtest), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e82015f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model\n",
    "\n",
    "dae_checkpoint = './dae_checkpoint/dae_model.h5'\n",
    "model.save(dae_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bb00ac5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image -> [1]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"image_input_34:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (None, 400, 600, 3).\n",
      "image -> [2]\n",
      "image -> [3]\n",
      "image -> [4]\n",
      "image -> [5]\n",
      "image -> [6]\n",
      "image -> [7]\n",
      "image -> [8]\n",
      "image -> [9]\n",
      "image -> [10]\n",
      "image -> [11]\n",
      "image -> [12]\n",
      "image -> [13]\n",
      "image -> [14]\n",
      "image -> [15]\n",
      "image -> [16]\n",
      "image -> [17]\n",
      "image -> [18]\n",
      "image -> [19]\n",
      "image -> [20]\n",
      "image -> [21]\n",
      "image -> [22]\n",
      "image -> [23]\n",
      "image -> [24]\n",
      "image -> [25]\n",
      "image -> [26]\n",
      "image -> [27]\n",
      "image -> [28]\n",
      "image -> [29]\n",
      "image -> [30]\n"
     ]
    }
   ],
   "source": [
    "# load the model and test\n",
    "\n",
    "f_model = load_model(dae_checkpoint)\n",
    "\n",
    "de_enhanced_path = './data/test/de_enhanced/'\n",
    "for i in range(test_df.shape[0]):\n",
    "    print('image -> [{}]'.format(i+1))\n",
    "    pred_temp = f_model.predict(test_df[i:(i+1)])\n",
    "    p_im = pred_temp[0,:,:,:]\n",
    "    p_im = (p_im)*255\n",
    "    p_im = np.clip(p_im, 0, 255)\n",
    "    p_im = p_im.astype(np.uint8)\n",
    "    p_im = cv.cvtColor(p_im, cv.COLOR_BGR2RGB)\n",
    "    cv.imwrite(de_enhanced_path+test_images_name[i][0]+'.'+test_images_name[i][1], p_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "011bba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_high_data_name = glob(os.path.join('./data/test/high')+'/*.*')\n",
    "enhanced_data_name = glob(os.path.join('./data/test/de_enhanced/')+'/*.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0f1b84cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr value --> 27.993\n"
     ]
    }
   ],
   "source": [
    "# Calculate psnr\n",
    "\n",
    "psnr_scores = []\n",
    "for idx in range(len(enhanced_data_name)):\n",
    "    low_im = cv.imread(test_high_data_name[idx])\n",
    "    enh_im = cv.imread(enhanced_data_name[idx])\n",
    "    psnr_scores.append(psnr_score(low_im, enh_im))\n",
    "\n",
    "\n",
    "# mean psnr\n",
    "psnr_val = np.round(np.mean(psnr_scores), 3)\n",
    "print('psnr value --> {}'.format(psnr_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2f4c2820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssim value --> 0.6988\n"
     ]
    }
   ],
   "source": [
    "# Calculate ssim\n",
    "\n",
    "ssim_scores = []\n",
    "for idx in range(len(enhanced_data_name)):\n",
    "    high_im = cv.imread(test_high_data_name[idx])\n",
    "    enh_im = cv.imread(enhanced_data_name[idx])\n",
    "    ssim_scores.append(ssim_score(high_im, enh_im))\n",
    "\n",
    "\n",
    "# mean psnr\n",
    "ssim_val = np.round(np.mean(ssim_scores), 4)\n",
    "print('ssim value --> {}'.format(ssim_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b7c7a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brisque value --> 68.8344\n"
     ]
    }
   ],
   "source": [
    "# calculate brisque\n",
    "\n",
    "brisque_scores = []\n",
    "for idx in range(len(enhanced_data_name)):\n",
    "    brisque_scores.append(brisque_score(enhanced_data_name[idx]))\n",
    "\n",
    "# mean brisque\n",
    "brisque_val = np.round(np.mean(brisque_scores), 4)\n",
    "print('brisque value --> {}'.format(brisque_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9da5f",
   "metadata": {},
   "source": [
    "#### Enhanced Images - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8574c99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image -> [1]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"image_input_32:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (None, 400, 600, 3).\n",
      "image -> [2]\n",
      "image -> [3]\n",
      "image -> [4]\n",
      "image -> [5]\n",
      "image -> [6]\n",
      "image -> [7]\n",
      "image -> [8]\n",
      "image -> [9]\n",
      "image -> [10]\n",
      "image -> [11]\n",
      "image -> [12]\n",
      "image -> [13]\n",
      "image -> [14]\n",
      "image -> [15]\n",
      "image -> [16]\n",
      "image -> [17]\n",
      "image -> [18]\n",
      "image -> [19]\n",
      "image -> [20]\n",
      "image -> [21]\n",
      "image -> [22]\n",
      "image -> [23]\n",
      "image -> [24]\n",
      "image -> [25]\n",
      "image -> [26]\n",
      "image -> [27]\n",
      "image -> [28]\n",
      "image -> [29]\n",
      "image -> [30]\n",
      "image -> [31]\n",
      "image -> [32]\n",
      "image -> [33]\n",
      "image -> [34]\n",
      "image -> [35]\n",
      "image -> [36]\n",
      "image -> [37]\n",
      "image -> [38]\n",
      "image -> [39]\n",
      "image -> [40]\n",
      "image -> [41]\n",
      "image -> [42]\n",
      "image -> [43]\n",
      "image -> [44]\n",
      "image -> [45]\n",
      "image -> [46]\n",
      "image -> [47]\n",
      "image -> [48]\n",
      "image -> [49]\n",
      "image -> [50]\n",
      "image -> [51]\n",
      "image -> [52]\n",
      "image -> [53]\n",
      "image -> [54]\n",
      "image -> [55]\n",
      "image -> [56]\n",
      "image -> [57]\n",
      "image -> [58]\n",
      "image -> [59]\n",
      "image -> [60]\n",
      "image -> [61]\n",
      "image -> [62]\n",
      "image -> [63]\n",
      "image -> [64]\n",
      "image -> [65]\n",
      "image -> [66]\n",
      "image -> [67]\n",
      "image -> [68]\n",
      "image -> [69]\n",
      "image -> [70]\n",
      "image -> [71]\n",
      "image -> [72]\n",
      "image -> [73]\n",
      "image -> [74]\n",
      "image -> [75]\n",
      "image -> [76]\n",
      "image -> [77]\n",
      "image -> [78]\n",
      "image -> [79]\n",
      "image -> [80]\n",
      "image -> [81]\n",
      "image -> [82]\n",
      "image -> [83]\n",
      "image -> [84]\n",
      "image -> [85]\n",
      "image -> [86]\n",
      "image -> [87]\n",
      "image -> [88]\n",
      "image -> [89]\n",
      "image -> [90]\n",
      "image -> [91]\n",
      "image -> [92]\n",
      "image -> [93]\n",
      "image -> [94]\n",
      "image -> [95]\n",
      "image -> [96]\n",
      "image -> [97]\n",
      "image -> [98]\n",
      "image -> [99]\n",
      "image -> [100]\n",
      "image -> [101]\n",
      "image -> [102]\n",
      "image -> [103]\n",
      "image -> [104]\n",
      "image -> [105]\n",
      "image -> [106]\n",
      "image -> [107]\n",
      "image -> [108]\n",
      "image -> [109]\n",
      "image -> [110]\n",
      "image -> [111]\n",
      "image -> [112]\n",
      "image -> [113]\n",
      "image -> [114]\n",
      "image -> [115]\n",
      "image -> [116]\n",
      "image -> [117]\n",
      "image -> [118]\n",
      "image -> [119]\n",
      "image -> [120]\n",
      "image -> [121]\n",
      "image -> [122]\n",
      "image -> [123]\n",
      "image -> [124]\n",
      "image -> [125]\n",
      "image -> [126]\n",
      "image -> [127]\n",
      "image -> [128]\n",
      "image -> [129]\n",
      "image -> [130]\n",
      "image -> [131]\n",
      "image -> [132]\n",
      "image -> [133]\n",
      "image -> [134]\n",
      "image -> [135]\n",
      "image -> [136]\n",
      "image -> [137]\n",
      "image -> [138]\n",
      "image -> [139]\n",
      "image -> [140]\n",
      "image -> [141]\n",
      "image -> [142]\n",
      "image -> [143]\n",
      "image -> [144]\n",
      "image -> [145]\n",
      "image -> [146]\n",
      "image -> [147]\n",
      "image -> [148]\n",
      "image -> [149]\n",
      "image -> [150]\n",
      "image -> [151]\n",
      "image -> [152]\n",
      "image -> [153]\n",
      "image -> [154]\n",
      "image -> [155]\n",
      "image -> [156]\n",
      "image -> [157]\n",
      "image -> [158]\n",
      "image -> [159]\n",
      "image -> [160]\n",
      "image -> [161]\n",
      "image -> [162]\n",
      "image -> [163]\n",
      "image -> [164]\n",
      "image -> [165]\n",
      "image -> [166]\n",
      "image -> [167]\n",
      "image -> [168]\n",
      "image -> [169]\n",
      "image -> [170]\n",
      "image -> [171]\n",
      "image -> [172]\n",
      "image -> [173]\n",
      "image -> [174]\n",
      "image -> [175]\n",
      "image -> [176]\n",
      "image -> [177]\n",
      "image -> [178]\n",
      "image -> [179]\n",
      "image -> [180]\n",
      "image -> [181]\n",
      "image -> [182]\n",
      "image -> [183]\n",
      "image -> [184]\n",
      "image -> [185]\n",
      "image -> [186]\n",
      "image -> [187]\n",
      "image -> [188]\n",
      "image -> [189]\n",
      "image -> [190]\n",
      "image -> [191]\n",
      "image -> [192]\n",
      "image -> [193]\n",
      "image -> [194]\n",
      "image -> [195]\n",
      "image -> [196]\n",
      "image -> [197]\n",
      "image -> [198]\n",
      "image -> [199]\n",
      "image -> [200]\n",
      "image -> [201]\n",
      "image -> [202]\n",
      "image -> [203]\n",
      "image -> [204]\n",
      "image -> [205]\n",
      "image -> [206]\n",
      "image -> [207]\n",
      "image -> [208]\n",
      "image -> [209]\n",
      "image -> [210]\n",
      "image -> [211]\n",
      "image -> [212]\n",
      "image -> [213]\n",
      "image -> [214]\n",
      "image -> [215]\n",
      "image -> [216]\n",
      "image -> [217]\n",
      "image -> [218]\n",
      "image -> [219]\n",
      "image -> [220]\n",
      "image -> [221]\n",
      "image -> [222]\n",
      "image -> [223]\n",
      "image -> [224]\n",
      "image -> [225]\n",
      "image -> [226]\n",
      "image -> [227]\n",
      "image -> [228]\n",
      "image -> [229]\n",
      "image -> [230]\n",
      "image -> [231]\n",
      "image -> [232]\n",
      "image -> [233]\n",
      "image -> [234]\n",
      "image -> [235]\n",
      "image -> [236]\n",
      "image -> [237]\n",
      "image -> [238]\n",
      "image -> [239]\n",
      "image -> [240]\n",
      "image -> [241]\n",
      "image -> [242]\n",
      "image -> [243]\n",
      "image -> [244]\n",
      "image -> [245]\n",
      "image -> [246]\n",
      "image -> [247]\n",
      "image -> [248]\n",
      "image -> [249]\n",
      "image -> [250]\n",
      "image -> [251]\n",
      "image -> [252]\n",
      "image -> [253]\n",
      "image -> [254]\n",
      "image -> [255]\n",
      "image -> [256]\n",
      "image -> [257]\n",
      "image -> [258]\n",
      "image -> [259]\n",
      "image -> [260]\n",
      "image -> [261]\n",
      "image -> [262]\n",
      "image -> [263]\n",
      "image -> [264]\n",
      "image -> [265]\n",
      "image -> [266]\n",
      "image -> [267]\n",
      "image -> [268]\n",
      "image -> [269]\n",
      "image -> [270]\n",
      "image -> [271]\n",
      "image -> [272]\n",
      "image -> [273]\n",
      "image -> [274]\n",
      "image -> [275]\n",
      "image -> [276]\n",
      "image -> [277]\n",
      "image -> [278]\n",
      "image -> [279]\n",
      "image -> [280]\n",
      "image -> [281]\n",
      "image -> [282]\n",
      "image -> [283]\n",
      "image -> [284]\n",
      "image -> [285]\n",
      "image -> [286]\n",
      "image -> [287]\n",
      "image -> [288]\n",
      "image -> [289]\n",
      "image -> [290]\n",
      "image -> [291]\n",
      "image -> [292]\n",
      "image -> [293]\n",
      "image -> [294]\n",
      "image -> [295]\n",
      "image -> [296]\n",
      "image -> [297]\n",
      "image -> [298]\n",
      "image -> [299]\n",
      "image -> [300]\n",
      "image -> [301]\n",
      "image -> [302]\n",
      "image -> [303]\n",
      "image -> [304]\n",
      "image -> [305]\n",
      "image -> [306]\n",
      "image -> [307]\n",
      "image -> [308]\n",
      "image -> [309]\n",
      "image -> [310]\n",
      "image -> [311]\n",
      "image -> [312]\n",
      "image -> [313]\n",
      "image -> [314]\n",
      "image -> [315]\n",
      "image -> [316]\n",
      "image -> [317]\n",
      "image -> [318]\n",
      "image -> [319]\n",
      "image -> [320]\n",
      "image -> [321]\n",
      "image -> [322]\n",
      "image -> [323]\n",
      "image -> [324]\n",
      "image -> [325]\n",
      "image -> [326]\n",
      "image -> [327]\n",
      "image -> [328]\n",
      "image -> [329]\n",
      "image -> [330]\n",
      "image -> [331]\n",
      "image -> [332]\n",
      "image -> [333]\n",
      "image -> [334]\n",
      "image -> [335]\n",
      "image -> [336]\n",
      "image -> [337]\n",
      "image -> [338]\n",
      "image -> [339]\n",
      "image -> [340]\n",
      "image -> [341]\n",
      "image -> [342]\n",
      "image -> [343]\n",
      "image -> [344]\n",
      "image -> [345]\n",
      "image -> [346]\n",
      "image -> [347]\n",
      "image -> [348]\n",
      "image -> [349]\n",
      "image -> [350]\n",
      "image -> [351]\n",
      "image -> [352]\n",
      "image -> [353]\n",
      "image -> [354]\n",
      "image -> [355]\n",
      "image -> [356]\n",
      "image -> [357]\n",
      "image -> [358]\n",
      "image -> [359]\n",
      "image -> [360]\n",
      "image -> [361]\n",
      "image -> [362]\n",
      "image -> [363]\n",
      "image -> [364]\n",
      "image -> [365]\n",
      "image -> [366]\n",
      "image -> [367]\n",
      "image -> [368]\n",
      "image -> [369]\n",
      "image -> [370]\n",
      "image -> [371]\n",
      "image -> [372]\n",
      "image -> [373]\n",
      "image -> [374]\n",
      "image -> [375]\n",
      "image -> [376]\n",
      "image -> [377]\n",
      "image -> [378]\n",
      "image -> [379]\n",
      "image -> [380]\n",
      "image -> [381]\n",
      "image -> [382]\n",
      "image -> [383]\n",
      "image -> [384]\n",
      "image -> [385]\n",
      "image -> [386]\n",
      "image -> [387]\n",
      "image -> [388]\n",
      "image -> [389]\n",
      "image -> [390]\n",
      "image -> [391]\n",
      "image -> [392]\n",
      "image -> [393]\n",
      "image -> [394]\n",
      "image -> [395]\n",
      "image -> [396]\n",
      "image -> [397]\n",
      "image -> [398]\n",
      "image -> [399]\n",
      "image -> [400]\n",
      "image -> [401]\n",
      "image -> [402]\n",
      "image -> [403]\n",
      "image -> [404]\n",
      "image -> [405]\n",
      "image -> [406]\n",
      "image -> [407]\n",
      "image -> [408]\n",
      "image -> [409]\n",
      "image -> [410]\n",
      "image -> [411]\n",
      "image -> [412]\n",
      "image -> [413]\n",
      "image -> [414]\n",
      "image -> [415]\n",
      "image -> [416]\n",
      "image -> [417]\n",
      "image -> [418]\n",
      "image -> [419]\n",
      "image -> [420]\n",
      "image -> [421]\n",
      "image -> [422]\n",
      "image -> [423]\n",
      "image -> [424]\n",
      "image -> [425]\n",
      "image -> [426]\n",
      "image -> [427]\n",
      "image -> [428]\n",
      "image -> [429]\n",
      "image -> [430]\n",
      "image -> [431]\n",
      "image -> [432]\n",
      "image -> [433]\n",
      "image -> [434]\n",
      "image -> [435]\n",
      "image -> [436]\n",
      "image -> [437]\n",
      "image -> [438]\n",
      "image -> [439]\n",
      "image -> [440]\n",
      "image -> [441]\n",
      "image -> [442]\n",
      "image -> [443]\n",
      "image -> [444]\n",
      "image -> [445]\n",
      "image -> [446]\n",
      "image -> [447]\n",
      "image -> [448]\n",
      "image -> [449]\n",
      "image -> [450]\n",
      "image -> [451]\n",
      "image -> [452]\n",
      "image -> [453]\n",
      "image -> [454]\n",
      "image -> [455]\n",
      "image -> [456]\n",
      "image -> [457]\n",
      "image -> [458]\n",
      "image -> [459]\n",
      "image -> [460]\n",
      "image -> [461]\n",
      "image -> [462]\n",
      "image -> [463]\n",
      "image -> [464]\n",
      "image -> [465]\n",
      "image -> [466]\n",
      "image -> [467]\n",
      "image -> [468]\n",
      "image -> [469]\n",
      "image -> [470]\n"
     ]
    }
   ],
   "source": [
    "# load the model and test\n",
    "\n",
    "f_model = load_model(dae_checkpoint)\n",
    "\n",
    "de_enhanced_path = './data/train/de_enhanced/'\n",
    "for i in range(train_df.shape[0]):\n",
    "    print('image -> [{}]'.format(i+1))\n",
    "    pred_temp = f_model.predict(train_df[i:(i+1)])\n",
    "    p_im = pred_temp[0,:,:,:]\n",
    "    p_im = (p_im)*255\n",
    "    p_im = np.clip(p_im, 0, 255)\n",
    "    p_im = p_im.astype(np.uint8)\n",
    "    p_im = cv.cvtColor(p_im, cv.COLOR_BGR2RGB)\n",
    "    cv.imwrite(de_enhanced_path+train_images_name[i][0]+'.'+train_images_name[i][1], p_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "de4f3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_high_data_name = glob(os.path.join('./data/train/high')+'/*.*')\n",
    "all_enhanced_data_name = glob(os.path.join('./data/train/de_enhanced/')+'/*.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8550f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr value --> 28.119\n"
     ]
    }
   ],
   "source": [
    "# Calculate psnr\n",
    "\n",
    "psnr_scores = []\n",
    "for idx in range(len(all_enhanced_data_name)):\n",
    "    high_im = cv.imread(all_high_data_name[idx])\n",
    "    enh_im = cv.imread(all_enhanced_data_name[idx])\n",
    "    psnr_scores.append(psnr_score(high_im, enh_im))\n",
    "\n",
    "\n",
    "# mean psnr\n",
    "psnr_val = np.round(np.mean(psnr_scores), 3)\n",
    "print('psnr value --> {}'.format(psnr_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bca15473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssim value --> 0.7048\n"
     ]
    }
   ],
   "source": [
    "# Calculate ssim\n",
    "\n",
    "ssim_scores = []\n",
    "for idx in range(len(all_enhanced_data_name)):\n",
    "    high_im = cv.imread(all_high_data_name[idx])\n",
    "    enh_im = cv.imread(all_enhanced_data_name[idx])\n",
    "    ssim_scores.append(ssim_score(high_im, enh_im))\n",
    "\n",
    "\n",
    "# mean psnr\n",
    "ssim_val = np.round(np.mean(ssim_scores), 4)\n",
    "print('ssim value --> {}'.format(ssim_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7ef906a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brisque value --> 69.7628\n"
     ]
    }
   ],
   "source": [
    "# calculate brisque\n",
    "\n",
    "brisque_scores = []\n",
    "for idx in range(len(all_enhanced_data_name)):\n",
    "    brisque_scores.append(brisque_score(all_enhanced_data_name[idx]))\n",
    "\n",
    "# mean brisque\n",
    "brisque_val = np.round(np.mean(brisque_scores), 4)\n",
    "print('brisque value --> {}'.format(brisque_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150130a",
   "metadata": {},
   "source": [
    "### ExDark Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "14275e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-2abd17a318cc>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  exdark_df = np.array(exdark_image)\n"
     ]
    }
   ],
   "source": [
    "exdark_images = sorted(os.listdir('./validation_data/ExDark/be_enhanced'))\n",
    "exdark_image = []\n",
    "for im in exdark_images:\n",
    "    img = image.load_img('./validation_data/ExDark/be_enhanced/'+ im, color_mode= 'rgb')\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    exdark_image.append(img)\n",
    "exdark_df = np.array(exdark_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc0b4afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exdark_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0adfbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "exdark_images_name = []\n",
    "for i in range(len(exdark_images)):\n",
    "    temp = []\n",
    "    temp.append(exdark_images[i].split('.')[0])\n",
    "    temp.append(exdark_images[i].split('.')[1])\n",
    "    exdark_images_name.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0e0c521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2015_00036', 'jpg'],\n",
       " ['2015_00056', 'jpg'],\n",
       " ['2015_00433', 'jpg'],\n",
       " ['2015_00636', 'jpg'],\n",
       " ['2015_00720', 'jpg']]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exdark_images_name[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a966344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image -> [1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-2d138f113ffb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexdark_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image -> [{}]'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpred_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexdark_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mp_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mp_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp_im\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1567\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1569\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1570\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1571\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m--> 263\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "# load the model and test\n",
    "\n",
    "f_model = load_model(dae_checkpoint)\n",
    "\n",
    "de_enhanced_path = './validation_data/ExDark/de_enhanced/'\n",
    "for i in range(exdark_df.shape[0]):\n",
    "    print('image -> [{}]'.format(i+1))\n",
    "    pred_temp = f_model.predict(exdark_df[i:(i+1)])\n",
    "    p_im = pred_temp[0,:,:,:]\n",
    "    p_im = (p_im)*255\n",
    "    p_im = np.clip(p_im, 0, 255)\n",
    "    p_im = p_im.astype(np.uint8)\n",
    "    p_im = cv.cvtColor(p_im, cv.COLOR_BGR2RGB)\n",
    "    cv.imwrite(de_enhanced_path+exdark_images_name[i][0]+'.'+exdark_images_name[i][1], p_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e852ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_enhanced_data_name = glob(os.path.join('./validation_data/ExDark/de_enhanced/')+'/*.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate brisque\n",
    "\n",
    "brisque_scores = []\n",
    "for idx in range(len(val_enhanced_data_name)):\n",
    "    brisque_scores.append(brisque_score(val_enhanced_data_name[idx]))\n",
    "\n",
    "# mean brisque\n",
    "brisque_val = np.round(np.mean(brisque_scores), 4)\n",
    "print('brisque value --> {}'.format(brisque_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4e952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "212300eb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
